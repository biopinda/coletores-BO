# Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Sistema de processamento de linguagem natural (NLP) para identificar, classificar e canonicalizar nomes de coletores de plantas em registros de herb√°rios digitais.

---

## üìã Sum√°rio

- [Sobre o Projeto](#-sobre-o-projeto)
- [O Problema](#-o-problema)
- [A Solu√ß√£o](#-a-solu√ß√£o)
- [Arquitetura T√©cnica](#-arquitetura-t√©cnica)
- [Instala√ß√£o](#-instala√ß√£o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Desenvolvimento](#-desenvolvimento)
- [Roadmap](#-roadmap)
- [Licen√ßa](#-licen√ßa)

---

## üåø Sobre o Projeto

Este projeto foi desenvolvido para resolver um problema cr√≠tico na curadoria de cole√ß√µes bot√¢nicas digitais: a inconsist√™ncia na representa√ß√£o de nomes de coletores de plantas.

Em bancos de dados de herb√°rios, o mesmo coletor pode aparecer de diversas formas:
- "Forzza, R.C."
- "Forzza, R."
- "R.C. Forzza"
- "Rafaela C. Forzza"

Essas varia√ß√µes dificultam an√°lises quantitativas, estudos de redes de colabora√ß√£o e a identifica√ß√£o correta de contribui√ß√µes cient√≠ficas individuais.

### Contexto

Com aproximadamente **4.6 milh√µes de registros** de plantas (kingdom = "Plantae") em bases de dados MongoDB de herb√°rios brasileiros, a padroniza√ß√£o manual √© invi√°vel. Este sistema automatiza o processo atrav√©s de um pipeline de NLP robusto e eficiente.

---

## üéØ O Problema

### Desafios Identificados

1. **M√∫ltiplas representa√ß√µes do mesmo coletor**
   - Varia√ß√µes de formata√ß√£o: "Silva, J." vs "J. Silva"
   - Diferentes n√≠veis de detalhe: "Santos, M." vs "Maria Santos"
   - Erros de digita√ß√£o e inconsist√™ncias

2. **Classifica√ß√£o amb√≠gua**
   - Nomes pr√≥prios individuais vs. grupos de pessoas
   - Institui√ß√µes vs. equipes de pesquisa
   - Registros sem identifica√ß√£o ("?", "sem coletor")

3. **Volume e Performance**
   - Processar 4.6 milh√µes de registros
   - Tempo limitado: m√°ximo 6 horas de processamento
   - Requisito: ‚â•213 registros/segundo

4. **Dados n√£o estruturados**
   - Strings livres com m√∫ltiplos formatos
   - Separadores variados (";", "&", "et al.")
   - Mistura de idiomas e caracteres especiais

---

## üí° A Solu√ß√£o

### Pipeline de Processamento em 4 Etapas

O sistema implementa um pipeline sequencial de transforma√ß√£o de dados:

```
Entrada: "Silva, J. & R.C. Forzza; Santos, M. et al."
    ‚Üì
[1] CLASSIFICA√á√ÉO ‚Üí "conjunto_pessoas" (confian√ßa: 0.95)
    ‚Üì
[2] ATOMIZA√á√ÉO ‚Üí ["Silva, J.", "R.C. Forzza", "Santos, M."]
    ‚Üì
[3] NORMALIZA√á√ÉO ‚Üí Para cada nome individual
    ‚Üì
[4] CANONICALIZA√á√ÉO ‚Üí Agrupamento por similaridade
    ‚Üì
Sa√≠da: Entidades can√¥nicas com varia√ß√µes agrupadas
```

### 1. Classifica√ß√£o

Categoriza cada string em **5 tipos** usando reconhecimento de padr√µes:

| Categoria | Descri√ß√£o | Exemplo |
|-----------|-----------|---------|
| **Pessoa** | Nome pr√≥prio individual | "Silva, J.C.", "Maria Santos" |
| **Conjunto de Pessoas** | M√∫ltiplos nomes para atomiza√ß√£o | "Silva, J.; Santos, M." |
| **Grupo de Pessoas** | Denomina√ß√£o gen√©rica sem nomes | "Equipe de pesquisa" |
| **Empresa/Institui√ß√£o** | Acr√¥nimos e c√≥digos | "EMBRAPA", "USP", "INPA" |
| **N√£o Determinado** | Sem identifica√ß√£o | "?", "sem coletor" |

**Confian√ßa m√≠nima**: 0.70 (classifica√ß√µes abaixo s√£o sinalizadas para revis√£o manual)

### 2. Atomiza√ß√£o

Separa conjuntos de pessoas em nomes individuais:

- **Separadores reconhecidos**: `;` (ponto-e-v√≠rgula), `&` (e comercial), `et al.`
- **Preserva formata√ß√£o original** para rastreabilidade
- **Registra ordem** dos nomes na string original

**Exemplo**:
```python
Input:  "Silva, J. & R.C. Forzza; Santos, M. et al."
Output: [
    {"text": "Silva, J.", "position": 0, "separator": "&"},
    {"text": "R.C. Forzza", "position": 1, "separator": ";"},
    {"text": "Santos, M.", "position": 2, "separator": "et al."}
]
```

### 3. Normaliza√ß√£o

Padroniza nomes para compara√ß√£o, aplicando **3 regras**:

1. **Remove espa√ßos extras**: `"  Silva,J.C. "` ‚Üí `"Silva,J.C."`
2. **Padroniza pontua√ß√£o**: `"Silva,J"` ‚Üí `"Silva, J"`
3. **Converte para mai√∫sculas**: `"Silva, j.c."` ‚Üí `"SILVA, J.C."`

**Importante**: A formata√ß√£o original √© **preservada** para exibi√ß√£o, enquanto a vers√£o normalizada √© usada apenas para matching.

### 4. Canonicaliza√ß√£o

Agrupa varia√ß√µes similares sob um **nome can√¥nico** usando algoritmos de similaridade combinados:

#### Algoritmos de Similaridade

| Algoritmo | Peso | Prop√≥sito |
|-----------|------|-----------|
| **Levenshtein** | 40% | Detecta erros de digita√ß√£o e transposi√ß√µes |
| **Jaro-Winkler** | 40% | Otimizado para strings curtas (sobrenomes) |
| **Phon√©tico (Metaphone)** | 20% | Captura varia√ß√µes fon√©ticas |

**Score final**: M√©dia ponderada ‚â• 0.70 para agrupamento

**Exemplo de agrupamento**:
```
Varia√ß√µes detectadas:
- "Forzza, R.C." (1523 ocorr√™ncias)
- "Forzza, R." (847 ocorr√™ncias)
- "R.C. Forzza" (234 ocorr√™ncias)
- "Rafaela C. Forzza" (89 ocorr√™ncias)

Nome can√¥nico: "Forzza, R.C."
Total de ocorr√™ncias: 2693
```

### Formato Can√¥nico

Para entidades do tipo **Pessoa**, o sistema aplica o formato padr√£o:

**"Sobrenome, Iniciais"**

Exemplos:
- Todas as varia√ß√µes de "Forzza" ‚Üí `"Forzza, R.C."`
- Todas as varia√ß√µes de "Silva" ‚Üí `"Silva, J."`

---

## üèóÔ∏è Arquitetura T√©cnica

### Stack Tecnol√≥gico

- **Linguagem**: Python 3.11+
- **Processamento NLP**:
  - `python-Levenshtein` - C√°lculo de dist√¢ncia de edi√ß√£o
  - `jellyfish` - Jaro-Winkler e algoritmos fon√©ticos (Metaphone, Soundex)
- **Banco de Dados**:
  - **MongoDB** - Fonte de dados (4.6M registros)
  - **DuckDB** - Armazenamento local otimizado para an√°lises
- **Manipula√ß√£o de Dados**:
  - `pymongo` - Cliente MongoDB
  - `pandas` - Exporta√ß√£o CSV e processamento tabular
  - `pydantic` - Valida√ß√£o de schemas e type safety
- **Interface**:
  - `click` - CLI intuitivo
  - `tqdm` - Barras de progresso

### Modelo de Dados

```sql
-- Tabela √∫nica desnormalizada (DuckDB)
CREATE TABLE canonical_entities (
    id INTEGER PRIMARY KEY,
    canonical_name TEXT NOT NULL,
    entity_type TEXT CHECK(entity_type IN
        ('Pessoa', 'GrupoPessoas', 'Empresa', 'NaoDeterminado')),
    classification_confidence REAL CHECK(0.70 <= value <= 1.0),
    grouping_confidence REAL CHECK(0.70 <= value <= 1.0),
    variations JSON NOT NULL, -- Array de varia√ß√µes
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
```

**Varia√ß√µes em JSON**:
```json
[
  {
    "variation_text": "Forzza, R.C.",
    "occurrence_count": 1523,
    "association_confidence": 0.95,
    "first_seen": "2025-10-03T10:15:00Z",
    "last_seen": "2025-10-03T14:30:00Z"
  }
]
```

### Performance

#### Requisitos

- **Throughput**: ‚â•213 registros/segundo
- **Tempo total**: ‚â§6 horas para 4.6M registros
- **Mem√≥ria**: Streaming eficiente (sem carregar todos os registros em RAM)

#### Estrat√©gia de Paraleliza√ß√£o

```
MongoDB (4.6M registros)
    ‚Üì
Batch Reader (chunks de 10K)
    ‚Üì
Worker Pool (8 processos paralelos)
    ‚Üì [Pipeline completo por batch]
    ‚Üì
Results Aggregator (DuckDB com WAL)
    ‚Üì
Banco de Dados Local
```

- **Multiprocessing**: 8 workers em CPU moderna
- **Batch processing**: Chunks de 10.000 registros
- **Cursor streaming**: MongoDB batch_size=1000 (efici√™ncia de mem√≥ria)

### Garantias de Qualidade

#### Limiar de Confian√ßa

Todas as opera√ß√µes respeitam **confian√ßa m√≠nima de 0.70**:

- ‚úÖ Confian√ßa ‚â• 0.70: Aceita automaticamente
- ‚ö†Ô∏è Confian√ßa < 0.70: Sinaliza para revis√£o manual

#### Type Safety

- **Pydantic models**: Valida√ß√£o em runtime
- **mypy strict mode**: Verifica√ß√£o est√°tica de tipos
- **100% type hints**: Todo c√≥digo p√∫blico tipado

#### Testes

- **Cobertura m√≠nima**: 80% (100% em l√≥gica de neg√≥cio)
- **Contract tests**: Schemas de entrada/sa√≠da
- **Integration tests**: 7 cen√°rios de aceita√ß√£o
- **Performance tests**: Benchmarks com pytest-benchmark

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.11 ou superior
- MongoDB rodando (local ou remoto)
- 4GB RAM m√≠nimo (8GB recomendado)

### Passos

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/biopinda/coletores-BO.git
cd coletores-BO
```

2. **Crie um ambiente virtual**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

4. **Configure o sistema**

Edite `config.yaml`:
```yaml
mongodb:
  uri: "mongodb://localhost:27017"
  database: "plant_samples"
  collection: "specimens"
  filter: { kingdom: "Plantae" }

local_db:
  type: "duckdb"
  path: "./data/canonical_entities.db"

processing:
  batch_size: 10000
  confidence_threshold: 0.70
```

---

## üíª Uso

### Processamento B√°sico

```bash
python src/cli.py --config config.yaml
```

### Op√ß√µes Avan√ßadas

```bash
python src/cli.py --config config.yaml 

# Processar apenas primeiros 100K registros (teste)
python src/cli.py --config config.yaml --max-records 100000

# Especificar arquivo de sa√≠da CSV customizado
python src/cli.py --config config.yaml --output ./meu_relatorio.csv
```

### Sa√≠das Geradas

1. **Banco de dados local**: `./data/canonical_entities.db` (DuckDB)
   - Cont√©m todas as entidades can√¥nicas e varia√ß√µes
   - Persistente para an√°lises futuras

2. **Relat√≥rio CSV**: `./output/canonical_report.csv`
   - 4 colunas: `canonical_name`, `entity_type`, `variations`, `occurrence_counts`
   - Separador: TAB (tabula√ß√£o)
   - Varia√ß√µes separadas por `;`
   - Contagens alinhadas com varia√ß√µes

**Exemplo do CSV** (separado por TAB):

```text
canonical_name    entity_type    variations                                   occurrence_counts
"Forzza, R.C."    Pessoa         "Forzza, R.C.;R.C. Forzza;Rafaela C. Forzza"    "1523;847;234"
"Silva, J."       Pessoa         "Silva, J.;J. Silva"                          "2891;1205"
"EMBRAPA"         Empresa        "EMBRAPA"                                      "45"
```

3. **Documenta√ß√£o de regras**: `./docs/rules.md`
   - Regras edit√°veis do algoritmo
   - Permite refinamento iterativo

---

## üìÇ Estrutura do Projeto

```
coletores-BO/
‚îú‚îÄ src/                        # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ pipeline/               # Est√°gios do pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ classifier.py       # Classifica√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ atomizer.py         # Atomiza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ normalizer.py       # Normaliza√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ canonicalizer.py    # Canonicaliza√ß√£o
‚îÇ   ‚îú‚îÄ algorithms/             # Algoritmos de similaridade
‚îÇ   ‚îÇ   ‚îú‚îÄ similarity.py       # Levenshtein, Jaro-Winkler
‚îÇ   ‚îÇ   ‚îî‚îÄ phonetic.py         # Metaphone, Soundex
‚îÇ   ‚îú‚îÄ models/                 # Modelos de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ entities.py         # Entidades Pydantic
‚îÇ   ‚îÇ   ‚îî‚îÄ schemas.py          # Schemas I/O
‚îÇ   ‚îú‚îÄ storage/                # Adaptadores de armazenamento
‚îÇ   ‚îÇ   ‚îú‚îÄ mongodb_client.py   # Cliente MongoDB
‚îÇ   ‚îÇ   ‚îî‚îÄ local_db.py         # Cliente DuckDB
‚îÇ   ‚îú‚îÄ cli.py                  # Interface CLI
‚îÇ   ‚îî‚îÄ config.py               # Gerenciamento de configura√ß√£o
‚îÇ
‚îú‚îÄ tests/                      # Testes automatizados
‚îÇ   ‚îú‚îÄ contract/               # Testes de contrato
‚îÇ   ‚îú‚îÄ integration/            # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ unit/                   # Testes unit√°rios
‚îÇ
‚îú‚îÄ docs/                       # Documenta√ß√£o
‚îÇ   ‚îî‚îÄ rules.md                # Regras edit√°veis do algoritmo
‚îÇ
‚îú‚îÄ specs/                      # Especifica√ß√µes do projeto
‚îÇ   ‚îî‚îÄ 001-especificacao-leia-o/
‚îÇ       ‚îú‚îÄ spec.md             # Especifica√ß√£o funcional
‚îÇ       ‚îú‚îÄ plan.md             # Plano de implementa√ß√£o
‚îÇ       ‚îú‚îÄ research.md         # Pesquisa t√©cnica
‚îÇ       ‚îú‚îÄ data-model.md       # Modelo de dados
‚îÇ       ‚îú‚îÄ quickstart.md       # Guia de valida√ß√£o
‚îÇ       ‚îú‚îÄ tasks.md            # 40 tarefas de implementa√ß√£o
‚îÇ       ‚îî‚îÄ contracts/          # Contratos de interface
‚îÇ
‚îú‚îÄ config.yaml                 # Configura√ß√£o principal
‚îú‚îÄ requirements.txt            # Depend√™ncias Python
‚îî‚îÄ README.md                   # Este arquivo
```

---

## üõ†Ô∏è Desenvolvimento

### Executar Testes

```bash
# Todos os testes
pytest tests/

# Apenas testes de contrato
pytest tests/contract/

# Com cobertura
pytest --cov=src --cov-report=term-missing

# Testes de performance
pytest tests/unit/test_algorithms.py --benchmark-only
```

### Verifica√ß√£o de Qualidade

```bash
# Type checking
mypy src/ --strict

# Linting
ruff check src/

# Formata√ß√£o
black --check src/
```

### Adicionar Novos Padr√µes de Classifica√ß√£o

Edite `docs/rules.md` e ajuste os padr√µes em `src/pipeline/classifier.py`:

```python
# Exemplo: adicionar novo padr√£o institucional
INSTITUTION_PATTERNS = [
    r'^EMBRAPA$',
    r'^USP$',
    r'^INPA$',
    r'^SEU_NOVO_PADRAO$',  # Adicione aqui
]
```

### Ajustar Pesos de Similaridade

Edite `config.yaml`:

```yaml
algorithms:
  similarity_weights:
    levenshtein: 0.5      # Aumentar peso de edi√ß√£o
    jaro_winkler: 0.3     # Reduzir peso de prefixo
    phonetic: 0.2         # Manter peso fon√©tico
```

---

## üó∫Ô∏è Roadmap

### Fase 1: Implementa√ß√£o Core (Atual)

- [x] Estrutura do projeto
- [x] Especifica√ß√µes e planejamento
- [x] Contratos de interface
- [ ] Implementa√ß√£o do pipeline (Tarefas T002-T030)
- [ ] Testes automatizados
- [ ] Valida√ß√£o com 4.6M registros

### Fase 2: Refinamento (Futuro)

- [ ] Interface web para revis√£o manual de baixa confian√ßa
- [ ] Dashboard de m√©tricas e visualiza√ß√µes
- [ ] API REST para integra√ß√£o com outros sistemas
- [ ] Suporte a m√∫ltiplos idiomas
- [ ] Machine Learning para aprimorar classifica√ß√£o

### Fase 3: Escalabilidade (Futuro)

- [ ] Processamento distribu√≠do (Dask/Spark)
- [ ] Cache inteligente de similaridades
- [ ] Exporta√ß√£o para m√∫ltiplos formatos (JSON, Parquet)
- [ ] Versionamento de entidades can√¥nicas

---

## üìä Especifica√ß√µes T√©cnicas Detalhadas

Para informa√ß√µes t√©cnicas completas, consulte:

- **Especifica√ß√£o Funcional**: `specs/001-especificacao-leia-o/spec.md`
- **Plano de Implementa√ß√£o**: `specs/001-especificacao-leia-o/plan.md`
- **Pesquisa T√©cnica**: `specs/001-especificacao-leia-o/research.md`
- **Modelo de Dados**: `specs/001-especificacao-leia-o/data-model.md`
- **Tarefas de Implementa√ß√£o**: `specs/001-especificacao-leia-o/tasks.md`

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## üìß Contato

**Projeto**: Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas
**Reposit√≥rio**: [https://github.com/biopinda/coletores-BO](https://github.com/biopinda/coletores-BO)
**Organiza√ß√£o**: BioPinda

---

## üôè Agradecimentos

- Herb√°rios brasileiros que disponibilizam dados abertos
- Comunidade cient√≠fica de bot√¢nica sistem√°tica
- Desenvolvedores das bibliotecas open-source utilizadas

---

Desenvolvido com üåø para a ci√™ncia bot√¢nica brasileira
