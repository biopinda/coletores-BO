# Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![AI Powered](https://img.shields.io/badge/AI-BERT%20NER-orange.svg)](docs/TECHNICAL-NER.md)

Sistema de processamento de linguagem natural (NLP) com **intelig√™ncia artificial** para identificar, classificar e canonicalizar nomes de coletores de plantas em registros de herb√°rios digitais.

---

## ü§ñ Destaques de Intelig√™ncia Artificial

Este sistema utiliza **modelos de IA de √∫ltima gera√ß√£o** para processar nomes complexos de coletores:

- **BERT NER (Named Entity Recognition)**: Modelo `pierreguillou/bert-base-cased-pt-lenerbr` treinado em portugu√™s brasileiro
- **Fallback Inteligente**: Ativado automaticamente para casos de baixa confian√ßa (<70%)
- **Precis√£o Aprimorada**: F1-score de ~96% para identifica√ß√£o de nomes de pessoas
- **Processamento H√≠brido**: Combina regras lingu√≠sticas + aprendizado profundo para m√°xima precis√£o

‚Üí **[üìñ Documenta√ß√£o T√©cnica Completa de IA](docs/TECHNICAL-NER.md)**

---

## üìã Sum√°rio

- [Sobre o Projeto](#-sobre-o-projeto)
- [O Problema](#-o-problema)
- [A Solu√ß√£o](#-a-solu√ß√£o)
- [Arquitetura T√©cnica](#-arquitetura-t√©cnica)
- [Instala√ß√£o](#-instala√ß√£o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Desenvolvimento](#-desenvolvimento)
- [Roadmap](#-roadmap)
- [Licen√ßa](#-licen√ßa)

---

## üåø Sobre o Projeto

Este projeto foi desenvolvido para resolver um problema cr√≠tico na curadoria de cole√ß√µes bot√¢nicas digitais: a inconsist√™ncia na representa√ß√£o de nomes de coletores de plantas.

Em bancos de dados de herb√°rios, o mesmo coletor pode aparecer de diversas formas:
- "Forzza, R.C."
- "Forzza, R."
- "R.C. Forzza"
- "Rafaela C. Forzza"

Essas varia√ß√µes dificultam an√°lises quantitativas, estudos de redes de colabora√ß√£o e a identifica√ß√£o correta de contribui√ß√µes cient√≠ficas individuais.

### Contexto

Com aproximadamente **4.6 milh√µes de registros** de plantas (kingdom = "Plantae") em bases de dados MongoDB de herb√°rios brasileiros, a padroniza√ß√£o manual √© invi√°vel. Este sistema automatiza o processo atrav√©s de um pipeline de NLP robusto, eficiente e **potencializado por IA**.

---

## üéØ O Problema

### Desafios Identificados

1. **M√∫ltiplas representa√ß√µes do mesmo coletor**
   - Varia√ß√µes de formata√ß√£o: "Silva, J." vs "J. Silva"
   - Diferentes n√≠veis de detalhe: "Santos, M." vs "Maria Santos"
   - Erros de digita√ß√£o e inconsist√™ncias

2. **Classifica√ß√£o amb√≠gua**
   - Nomes pr√≥prios individuais vs. grupos de pessoas
   - Institui√ß√µes vs. equipes de pesquisa
   - Registros sem identifica√ß√£o ("?", "sem coletor")

3. **Volume e Performance**
   - Processar 4.6 milh√µes de registros
   - Tempo limitado: m√°ximo 6 horas de processamento
   - Requisito: ‚â•213 registros/segundo

4. **Dados n√£o estruturados**
   - Strings livres com m√∫ltiplos formatos
   - Separadores variados (";", "&", "et al.")
   - Mistura de idiomas e caracteres especiais

---

## üí° A Solu√ß√£o

### Pipeline de Processamento em 4 Etapas com IA

O sistema implementa um pipeline sequencial de transforma√ß√£o de dados potencializado por **aprendizado profundo**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ENTRADA: "Silva, J. & R.C. Forzza; Santos, M. et al."      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [1] CLASSIFICA√á√ÉO (com IA)                                  ‚îÇ
‚îÇ     ‚Ä¢ An√°lise por regras lingu√≠sticas                       ‚îÇ
‚îÇ     ‚Ä¢ Confian√ßa inicial: 0.95 ‚Üí "conjunto_pessoas"          ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ     ‚îÇ ü§ñ AI FALLBACK (se confian√ßa < 0.70)‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ BERT NER analisa entidades        ‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ Boost de confian√ßa: 0.65 ‚Üí 0.82+  ‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ Timeout: 5s por infer√™ncia        ‚îÇ                 ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [2] ATOMIZA√á√ÉO                                               ‚îÇ
‚îÇ     Sa√≠da: ["Silva, J.", "R.C. Forzza", "Santos, M."]      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [3] NORMALIZA√á√ÉO                                             ‚îÇ
‚îÇ     ‚Ä¢ Remove acentos, converte uppercase                    ‚îÇ
‚îÇ     ‚Ä¢ Padroniza formato: "FORZZA, R.C."                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [4] CANONICALIZA√á√ÉO                                          ‚îÇ
‚îÇ     ‚Ä¢ Similaridade: Levenshtein + Jaro-Winkler + Fon√©tica  ‚îÇ
‚îÇ     ‚Ä¢ Agrupamento: "Forzza, R.C." ‚Üê varia√ß√µes similares     ‚îÇ
‚îÇ     ‚Ä¢ Armazena em DuckDB com confian√ßa                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SA√çDA: Entidades can√¥nicas + varia√ß√µes + CSV                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. Classifica√ß√£o com IA

Categoriza cada string em **5 tipos** usando reconhecimento de padr√µes **h√≠brido** (regras + IA):

| Categoria | Descri√ß√£o | Exemplo |
|-----------|-----------|---------|
| **Pessoa** | Nome pr√≥prio individual | "Silva, J.C.", "Maria Santos" |
| **Conjunto de Pessoas** | M√∫ltiplos nomes para atomiza√ß√£o | "Silva, J.; Santos, M." |
| **Grupo de Pessoas** | Denomina√ß√£o gen√©rica sem nomes | "Equipe de pesquisa" |
| **Empresa/Institui√ß√£o** | Acr√¥nimos e c√≥digos | "EMBRAPA", "USP", "INPA" |
| **N√£o Determinado** | Sem identifica√ß√£o | "?", "sem coletor" |

**Confian√ßa m√≠nima**: 0.70

#### ü§ñ Fallback de IA

Para strings complexas ou com confian√ßa < 0.70:
- **Modelo BERT** analisa entidades nomeadas
- **Boost de confian√ßa**: Tipicamente 0.65 ‚Üí 0.82+
- **Performance**: ~2s por caso (apenas casos dif√≠ceis)

‚Üí **[Detalhes t√©cnicos do BERT NER](docs/TECHNICAL-NER.md)**

### 2. Atomiza√ß√£o

Separa conjuntos de pessoas em nomes individuais:

- **Separadores reconhecidos**: `;` (ponto-e-v√≠rgula), `&` (e comercial), `et al.`
- **Preserva formata√ß√£o original** para rastreabilidade
- **Registra ordem** dos nomes na string original

**Exemplo**:
```python
Input:  "Silva, J. & R.C. Forzza; Santos, M. et al."
Output: [
    {"text": "Silva, J.", "position": 0, "separator": "&"},
    {"text": "R.C. Forzza", "position": 1, "separator": ";"},
    {"text": "Santos, M.", "position": 2, "separator": "et al."}
]
```

### 3. Normaliza√ß√£o

Padroniza nomes para compara√ß√£o, aplicando **3 regras**:

1. **Remove espa√ßos extras**: `"  Silva,J.C. "` ‚Üí `"Silva,J.C."`
2. **Padroniza pontua√ß√£o**: `"Silva,J"` ‚Üí `"Silva, J"`
3. **Converte para mai√∫sculas**: `"Silva, j.c."` ‚Üí `"SILVA, J.C."`

**Importante**: A formata√ß√£o original √© **preservada** para exibi√ß√£o, enquanto a vers√£o normalizada √© usada apenas para matching.

### 4. Canonicaliza√ß√£o

Agrupa varia√ß√µes similares sob um **nome can√¥nico** usando algoritmos de similaridade combinados:

#### Algoritmos de Similaridade

| Algoritmo | Peso | Prop√≥sito |
|-----------|------|-----------|
| **Levenshtein** | 40% | Detecta erros de digita√ß√£o e transposi√ß√µes |
| **Jaro-Winkler** | 40% | Otimizado para strings curtas (sobrenomes) |
| **Phon√©tico (Metaphone)** | 20% | Captura varia√ß√µes fon√©ticas |

**Score final**: M√©dia ponderada ‚â• 0.70 para agrupamento

**Exemplo de agrupamento**:
```
Varia√ß√µes detectadas:
- "Forzza, R.C." (1523 ocorr√™ncias)
- "Forzza, R." (847 ocorr√™ncias)
- "R.C. Forzza" (234 ocorr√™ncias)
- "Rafaela C. Forzza" (89 ocorr√™ncias)

Nome can√¥nico: "Forzza, R.C."
Total de ocorr√™ncias: 2693
```

### Formato Can√¥nico

Para entidades do tipo **Pessoa**, o sistema aplica o formato padr√£o:

**"Sobrenome, Iniciais"**

Exemplos:
- Todas as varia√ß√µes de "Forzza" ‚Üí `"Forzza, R.C."`
- Todas as varia√ß√µes de "Silva" ‚Üí `"Silva, J."`

---

## üèóÔ∏è Arquitetura T√©cnica

### Stack Tecnol√≥gico

- **Linguagem**: Python 3.11+
- **Intelig√™ncia Artificial**:
  - **`transformers`** - Hugging Face BERT models
  - **`torch`** - PyTorch para infer√™ncia de deep learning
  - Modelo: `pierreguillou/bert-base-cased-pt-lenerbr` (420MB)
- **Processamento NLP**:
  - `python-Levenshtein` - C√°lculo de dist√¢ncia de edi√ß√£o
  - `jellyfish` - Jaro-Winkler e algoritmos fon√©ticos (Metaphone, Soundex)
- **Banco de Dados**:
  - **MongoDB** - Fonte de dados (4.6M registros)
  - **DuckDB** - Armazenamento local otimizado para an√°lises
- **Manipula√ß√£o de Dados**:
  - `pymongo` - Cliente MongoDB
  - `pandas` - Exporta√ß√£o CSV e processamento tabular
  - `pydantic` - Valida√ß√£o de schemas e type safety
- **Interface**:
  - `click` - CLI intuitivo
  - `tqdm` - Barras de progresso

### Modelo de Dados

```sql
-- Tabela √∫nica desnormalizada (DuckDB)
CREATE TABLE canonical_entities (
  id INTEGER PRIMARY KEY,
  canonicalName TEXT NOT NULL,
  entityType TEXT CHECK(entityType IN
    ('Pessoa', 'GrupoPessoas', 'Empresa', 'NaoDeterminado')),
  classification_confidence REAL CHECK(0.70 <= value <= 1.0),
  grouping_confidence REAL CHECK(0.70 <= value <= 1.0),
  variations JSON NOT NULL, -- Array de varia√ß√µes
  created_at TIMESTAMP,
  updated_at TIMESTAMP
);
```

**Varia√ß√µes em JSON**:
```json
[
  {
    "variation_text": "Forzza, R.C.",
    "occurrence_count": 1523,
    "association_confidence": 0.95,
    "first_seen": "2025-10-03T10:15:00Z",
    "last_seen": "2025-10-03T14:30:00Z"
  }
]
```

### Performance

#### Requisitos

- **Throughput**: ‚â•213 registros/segundo
- **Tempo total**: ‚â§6 horas para 4.6M registros
- **Overhead de IA**: ~2s por caso de baixa confian√ßa (pequena fra√ß√£o do total)
- **Mem√≥ria**: Streaming eficiente (sem carregar todos os registros em RAM)

#### Estrat√©gia de Paraleliza√ß√£o

```
MongoDB (4.6M registros)
    ‚Üì
Batch Reader (chunks de 10K)
    ‚Üì
Worker Pool (8 processos paralelos)
    ‚Üì [Pipeline completo por batch]
    ‚Üì
Results Aggregator (DuckDB com WAL)
    ‚Üì
Banco de Dados Local
```

- **Multiprocessing**: 8 workers em CPU moderna
- **Batch processing**: Chunks de 10.000 registros
- **Cursor streaming**: MongoDB batch_size=1000 (efici√™ncia de mem√≥ria)
- **Modelo BERT**: Carregado uma vez em mem√≥ria e cacheado

### Garantias de Qualidade

#### Limiar de Confian√ßa

Todas as opera√ß√µes respeitam **confian√ßa m√≠nima de 0.70**:

- ‚úÖ Confian√ßa ‚â• 0.70: Aceita automaticamente
- ü§ñ Confian√ßa < 0.70: Tenta fallback de IA BERT
- ‚ö†Ô∏è Ainda < 0.70 ap√≥s IA: Sinaliza para revis√£o manual

#### Type Safety

- **Pydantic models**: Valida√ß√£o em runtime
- **mypy strict mode**: Verifica√ß√£o est√°tica de tipos
- **100% type hints**: Todo c√≥digo p√∫blico tipado

#### Testes

- **Cobertura m√≠nima**: 80% (100% em l√≥gica de neg√≥cio)
- **Contract tests**: Schemas de entrada/sa√≠da (incluindo NER)
- **Integration tests**: 7 cen√°rios de aceita√ß√£o
- **Performance tests**: Benchmarks com pytest-benchmark

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.11 ou superior
- MongoDB rodando (local ou remoto)
- 4GB RAM m√≠nimo (8GB recomendado para modelo BERT)

### Passos

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/biopinda/coletores-BO.git
cd coletores-BO
```

2. **Crie um ambiente virtual**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

**Nota**: O primeiro uso far√° download autom√°tico do modelo BERT (~420MB) do Hugging Face.

4. **Configure o sistema**

Edite `config.yaml`:
```yaml
mongodb:
  uri: "mongodb://localhost:27017"
  database: "plant_samples"
  collection: "specimens"
  filter: { kingdom: "Plantae" }

local_db:
  type: "duckdb"
  path: "./data/canonical_entities.db"

processing:
  batch_size: 10000
  confidence_threshold: 0.70

ai:
  ner_model: "pierreguillou/bert-base-cased-pt-lenerbr"
  ner_timeout: 5  # segundos
  enable_fallback: true
```

---

## üíª Uso

### Processamento B√°sico

```bash
python src/cli.py --config config.yaml
```

### Op√ß√µes Avan√ßadas

```bash
# Processar apenas primeiros 100K registros (teste)
python src/cli.py --config config.yaml --max-records 100000

# Especificar arquivo de sa√≠da CSV customizado
python src/cli.py --config config.yaml --output ./meu_relatorio.csv

# Modo verbose com m√©tricas de IA
python src/cli.py --config config.yaml --verbose

# Desabilitar fallback de IA (apenas regras)
python src/cli.py --config config.yaml --no-ai
```

### Monitoramento de IA

No modo verbose (`--verbose`), o sistema exibe m√©tricas de uso de IA:

```
[INFO] Processing 4,600,000 records...
[INFO] BERT model loaded and cached
[PROGRESS] ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 80% | 3.68M/4.6M | 215 rec/s
[STATS] NER Invocations: 12,450 (0.27% of records)
[STATS] Avg Confidence Boost: 0.65 ‚Üí 0.82
[STATS] NER Total Time: 24,900s (~2s per case)
```

### Sa√≠das Geradas

1. **Banco de dados local**: `./data/canonical_entities.db` (DuckDB)
   - Cont√©m todas as entidades can√¥nicas e varia√ß√µes
   - Persistente para an√°lises futuras

2. **Relat√≥rio CSV**: `./output/canonical_report.csv`
   - 4 colunas: `canonicalName`, `entityType`, `variations`, `occurrenceCounts`
   - Separador: TAB (tabula√ß√£o)
   - Varia√ß√µes separadas por `;`
   - Contagens alinhadas com varia√ß√µes

**Exemplo do CSV** (separado por TAB):

```text
canonicalName    entityType    variations                                   occurrenceCounts
"Forzza, R.C."    Pessoa         Forzza, R.C.;R.C. Forzza;Rafaela C. Forzza    1523;847;234
"Silva, J."       Pessoa         Silva, J.;J. Silva                          2891;1205
"EMBRAPA"         Empresa        EMBRAPA                                      45
```

3. **Documenta√ß√£o de regras**: `./docs/rules.md`
   - Regras edit√°veis do algoritmo
   - Permite refinamento iterativo

---

## üìÇ Estrutura do Projeto

```
coletores-BO/
‚îú‚îÄ src/                        # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ pipeline/               # Est√°gios do pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ classifier.py       # Classifica√ß√£o (com IA)
‚îÇ   ‚îÇ   ‚îú‚îÄ atomizer.py         # Atomiza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ normalizer.py       # Normaliza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ canonicalizer.py    # Canonicaliza√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ ner_fallback.py     # ü§ñ BERT NER fallback
‚îÇ   ‚îú‚îÄ algorithms/             # Algoritmos de similaridade
‚îÇ   ‚îÇ   ‚îú‚îÄ similarity.py       # Levenshtein, Jaro-Winkler
‚îÇ   ‚îÇ   ‚îî‚îÄ phonetic.py         # Metaphone, Soundex
‚îÇ   ‚îú‚îÄ models/                 # Modelos de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ entities.py         # Entidades Pydantic
‚îÇ   ‚îÇ   ‚îî‚îÄ schemas.py          # Schemas I/O
‚îÇ   ‚îú‚îÄ storage/                # Adaptadores de armazenamento
‚îÇ   ‚îÇ   ‚îú‚îÄ mongodb_client.py   # Cliente MongoDB
‚îÇ   ‚îÇ   ‚îî‚îÄ local_db.py         # Cliente DuckDB
‚îÇ   ‚îú‚îÄ cli.py                  # Interface CLI
‚îÇ   ‚îî‚îÄ config.py               # Gerenciamento de configura√ß√£o
‚îÇ
‚îú‚îÄ tests/                      # Testes automatizados
‚îÇ   ‚îú‚îÄ contract/               # Testes de contrato (inc. NER)
‚îÇ   ‚îú‚îÄ integration/            # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ unit/                   # Testes unit√°rios (inc. NER)
‚îÇ
‚îú‚îÄ docs/                       # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ rules.md                # Regras edit√°veis do algoritmo
‚îÇ   ‚îî‚îÄ TECHNICAL-NER.md        # ü§ñ Documenta√ß√£o t√©cnica de IA
‚îÇ
‚îú‚îÄ specs/                      # Especifica√ß√µes do projeto
‚îÇ   ‚îî‚îÄ main/
‚îÇ       ‚îú‚îÄ spec.md             # Especifica√ß√£o funcional
‚îÇ       ‚îú‚îÄ plan.md             # Plano de implementa√ß√£o
‚îÇ       ‚îú‚îÄ research.md         # Pesquisa t√©cnica
‚îÇ       ‚îú‚îÄ data-model.md       # Modelo de dados
‚îÇ       ‚îú‚îÄ quickstart.md       # Guia de valida√ß√£o
‚îÇ       ‚îú‚îÄ tasks.md            # 43 tarefas de implementa√ß√£o
‚îÇ       ‚îî‚îÄ contracts/          # Contratos de interface
‚îÇ
‚îú‚îÄ config.yaml                 # Configura√ß√£o principal
‚îú‚îÄ requirements.txt            # Depend√™ncias Python
‚îî‚îÄ README.md                   # Este arquivo
```

---

## üõ†Ô∏è Desenvolvimento

### Executar Testes

```bash
# Todos os testes
pytest tests/

# Apenas testes de contrato
pytest tests/contract/

# Com cobertura
pytest --cov=src --cov-report=term-missing

# Testes de performance
pytest tests/unit/test_algorithms.py --benchmark-only

# Testes espec√≠ficos de IA
pytest tests/unit/test_ner_fallback.py -v
```

### Verifica√ß√£o de Qualidade

```bash
# Type checking
mypy src/ --strict

# Linting
ruff check src/

# Formata√ß√£o
black --check src/
```

### Adicionar Novos Padr√µes de Classifica√ß√£o

Edite `docs/rules.md` e ajuste os padr√µes em `src/pipeline/classifier.py`:

```python
# Exemplo: adicionar novo padr√£o institucional
INSTITUTION_PATTERNS = [
    r'^EMBRAPA$',
    r'^USP$',
    r'^INPA$',
    r'^SEU_NOVO_PADRAO$',  # Adicione aqui
]
```

### Ajustar Pesos de Similaridade

Edite `config.yaml`:

```yaml
algorithms:
  similarity_weights:
    levenshtein: 0.5      # Aumentar peso de edi√ß√£o
    jaro_winkler: 0.3     # Reduzir peso de prefixo
    phonetic: 0.2         # Manter peso fon√©tico
```

---

## üó∫Ô∏è Roadmap

### Fase 1: Implementa√ß√£o Core (Atual)

- [x] Estrutura do projeto
- [x] Especifica√ß√µes e planejamento
- [x] Contratos de interface
- [x] Integra√ß√£o de IA (BERT NER)
- [ ] Implementa√ß√£o completa do pipeline (Tarefas T002-T030)
- [ ] Testes automatizados
- [ ] Valida√ß√£o com 4.6M registros

### Fase 2: Refinamento (Futuro)

- [ ] Interface web para revis√£o manual de baixa confian√ßa
- [ ] Dashboard de m√©tricas e visualiza√ß√µes de IA
- [ ] API REST para integra√ß√£o com outros sistemas
- [ ] Fine-tuning do modelo BERT com dados espec√≠ficos de herb√°rios
- [ ] Suporte a m√∫ltiplos idiomas

### Fase 3: Escalabilidade (Futuro)

- [ ] Processamento distribu√≠do (Dask/Spark)
- [ ] Cache inteligente de similaridades
- [ ] Exporta√ß√£o para m√∫ltiplos formatos (JSON, Parquet)
- [ ] Versionamento de entidades can√¥nicas
- [ ] GPU acceleration para infer√™ncia de BERT

---

## üìä Especifica√ß√µes T√©cnicas Detalhadas

Para informa√ß√µes t√©cnicas completas, consulte:

- **ü§ñ Documenta√ß√£o de IA**: `docs/TECHNICAL-NER.md` ‚Üê **NOVO**
- **Especifica√ß√£o Funcional**: `specs/main/spec.md`
- **Plano de Implementa√ß√£o**: `specs/main/plan.md`
- **Pesquisa T√©cnica**: `specs/main/research.md`
- **Modelo de Dados**: `specs/main/data-model.md`
- **Tarefas de Implementa√ß√£o**: `specs/main/tasks.md`

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## üìß Contato

**Projeto**: Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas
**Reposit√≥rio**: [https://github.com/biopinda/coletores-BO](https://github.com/biopinda/coletores-BO)
**Organiza√ß√£o**: BioPinda

---

## üôè Agradecimentos

- Herb√°rios brasileiros que disponibilizam dados abertos
- Comunidade cient√≠fica de bot√¢nica sistem√°tica
- Desenvolvedores das bibliotecas open-source utilizadas
- **Hugging Face** pela plataforma de modelos de IA
- **Pierre Guillou** pelo modelo BERT em portugu√™s brasileiro

---

Desenvolvido com üåø e ü§ñ para a ci√™ncia bot√¢nica brasileira
