# Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![AI Powered](https://img.shields.io/badge/AI-BERT%20NER-orange.svg)](docs/NER_Implementation.md)

Sistema de processamento de linguagem natural (NLP) com **intelig√™ncia artificial** para identificar, classificar e canonicalizar nomes de coletores de plantas em registros de herb√°rios digitais.

---

## ü§ñ Destaques de Intelig√™ncia Artificial

Este sistema utiliza **modelos de IA de √∫ltima gera√ß√£o** para processar nomes complexos de coletores:

- **BERT NER (Named Entity Recognition)**: Modelo `pierreguillou/bert-base-cased-pt-lenerbr` treinado em portugu√™s brasileiro
- **Fallback Inteligente**: Ativado automaticamente para casos de baixa confian√ßa (<70%)
- **Acelera√ß√£o por GPU**: 66x mais r√°pido com CUDA (0.03s vs 2s por texto)
- **Processamento H√≠brido**: Combina regras lingu√≠sticas + aprendizado profundo para m√°xima precis√£o

‚Üí **[üìñ Documenta√ß√£o T√©cnica Completa de IA](docs/NER_Implementation.md)**

---

## üìã Sum√°rio

- [Sobre o Projeto](#-sobre-o-projeto)
- [O Problema](#-o-problema)
- [A Solu√ß√£o](#-a-solu√ß√£o)
- [Arquitetura T√©cnica](#-arquitetura-t√©cnica)
- [Instala√ß√£o](#-instala√ß√£o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Desenvolvimento](#-desenvolvimento)
- [Roadmap](#-roadmap)
- [Licen√ßa](#-licen√ßa)

---

## üåø Sobre o Projeto

Este projeto foi desenvolvido para resolver um problema cr√≠tico na curadoria de cole√ß√µes bot√¢nicas digitais: a inconsist√™ncia na representa√ß√£o de nomes de coletores de plantas.

Em bancos de dados de herb√°rios, o mesmo coletor pode aparecer de diversas formas:
- "Forzza, R.C."
- "Forzza, R."
- "R.C. Forzza"
- "Rafaela C. Forzza"

Essas varia√ß√µes dificultam an√°lises quantitativas, estudos de redes de colabora√ß√£o e a identifica√ß√£o correta de contribui√ß√µes cient√≠ficas individuais.

### Contexto

Com aproximadamente **4.6 milh√µes de registros** de plantas (kingdom = "Plantae") em bases de dados MongoDB de herb√°rios brasileiros, a padroniza√ß√£o manual √© invi√°vel. Este sistema automatiza o processo atrav√©s de um pipeline de NLP robusto, eficiente e **potencializado por IA**.

---

## üéØ O Problema

### Desafios Identificados

1. **M√∫ltiplas representa√ß√µes do mesmo coletor**
   - Varia√ß√µes de formata√ß√£o: "Silva, J." vs "J. Silva"
   - Diferentes n√≠veis de detalhe: "Santos, M." vs "Maria Santos"
   - Erros de digita√ß√£o e inconsist√™ncias

2. **Classifica√ß√£o amb√≠gua**
   - Nomes pr√≥prios individuais vs. grupos de pessoas
   - Institui√ß√µes vs. equipes de pesquisa
   - Registros sem identifica√ß√£o ("?", "sem coletor")

3. **Volume e Performance**
   - Processar 4.6 milh√µes de registros
   - Tempo limitado: m√°ximo 6 horas de processamento
   - Requisito: ‚â•213 registros/segundo

4. **Dados n√£o estruturados**
   - Strings livres com m√∫ltiplos formatos
   - Separadores variados (";", "&", "et al.")
   - Mistura de idiomas e caracteres especiais

---

## üí° A Solu√ß√£o

### Pipeline de Processamento em 4 Etapas com IA

O sistema implementa um pipeline sequencial de transforma√ß√£o de dados potencializado por **aprendizado profundo**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ENTRADA: "Silva, J. & R.C. Forzza; Santos, M. et al."      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [1] CLASSIFICA√á√ÉO (com IA)                                  ‚îÇ
‚îÇ     ‚Ä¢ An√°lise por regras lingu√≠sticas                       ‚îÇ
‚îÇ     ‚Ä¢ Confian√ßa inicial: 0.95 ‚Üí "conjunto_pessoas"          ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ     ‚îÇ ü§ñ AI FALLBACK (se confian√ßa < 0.70)‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ BERT NER analisa entidades        ‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ Boost de confian√ßa: 0.65 ‚Üí 0.82+  ‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ GPU: 0.03s por infer√™ncia         ‚îÇ                 ‚îÇ
‚îÇ     ‚îÇ ‚Ä¢ CPU: 2s por infer√™ncia            ‚îÇ                 ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [2] ATOMIZA√á√ÉO                                               ‚îÇ
‚îÇ     Sa√≠da: ["Silva, J.", "R.C. Forzza", "Santos, M."]      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [3] NORMALIZA√á√ÉO                                             ‚îÇ
‚îÇ     ‚Ä¢ Remove acentos, converte uppercase                    ‚îÇ
‚îÇ     ‚Ä¢ Padroniza formato: "FORZZA, R.C."                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [4] CANONICALIZA√á√ÉO                                          ‚îÇ
‚îÇ     ‚Ä¢ Similaridade: Levenshtein + Jaro-Winkler + Fon√©tica  ‚îÇ
‚îÇ     ‚Ä¢ Agrupamento: "Forzza, R.C." ‚Üê varia√ß√µes similares     ‚îÇ
‚îÇ     ‚Ä¢ Armazena em DuckDB com confian√ßa                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SA√çDA: Entidades can√¥nicas + varia√ß√µes + CSV                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. Classifica√ß√£o com IA

Categoriza cada string em **5 tipos** usando reconhecimento de padr√µes **h√≠brido** (regras + IA):

| Categoria | Descri√ß√£o | Exemplo |
|-----------|-----------|---------|
| **Pessoa** | Nome pr√≥prio individual | "Silva, J.C.", "Maria Santos" |
| **Conjunto de Pessoas** | M√∫ltiplos nomes para atomiza√ß√£o | "Silva, J.; Santos, M." |
| **Grupo de Pessoas** | Denomina√ß√£o gen√©rica sem nomes | "Equipe de pesquisa" |
| **Empresa/Institui√ß√£o** | Acr√¥nimos e c√≥digos | "EMBRAPA", "USP", "INPA" |
| **N√£o Determinado** | Sem identifica√ß√£o | "?", "sem coletor" |

**Confian√ßa m√≠nima**: 0.70

#### ü§ñ Fallback de IA (IMPLEMENTADO)

Para strings complexas ou com confian√ßa < 0.70:
- **Modelo**: `pierreguillou/bert-base-cased-pt-lenerbr` (Portuguese BERT)
- **Ativa√ß√£o**: Autom√°tica quando confian√ßa < 0.70
- **Boost de Confian√ßa**:
  - Pessoa detectada (score > 0.85): +0.15
  - Pessoa detectada (score > 0.70): +0.10
  - Pessoa detectada (score < 0.70): +0.05
  - Organiza√ß√£o detectada: +0.05
- **Performance GPU** (NVIDIA GTX 1060): 0.03s por texto
- **Performance CPU**: 2s por texto
- **Uso de Mem√≥ria GPU**: 414 MB
- **Lazy Loading**: Modelo carrega apenas quando necess√°rio

‚Üí **[Detalhes t√©cnicos do BERT NER](docs/NER_Implementation.md)**

### 2. Atomiza√ß√£o

Separa conjuntos de pessoas em nomes individuais:

- **Separadores reconhecidos**: `;` (ponto-e-v√≠rgula), `&` (e comercial), `et al.`
- **Preserva formata√ß√£o original** para rastreabilidade
- **Registra ordem** dos nomes na string original

**Exemplo**:
```python
Input:  "Silva, J. & R.C. Forzza; Santos, M. et al."
Output: [
    {"text": "Silva, J.", "position": 0, "separator": "&"},
    {"text": "R.C. Forzza", "position": 1, "separator": ";"},
    {"text": "Santos, M.", "position": 2, "separator": "et al."}
]
```

### 3. Normaliza√ß√£o

Padroniza nomes para compara√ß√£o, aplicando **3 regras**:

1. **Remove espa√ßos extras**: `"  Silva,J.C. "` ‚Üí `"Silva,J.C."`
2. **Padroniza pontua√ß√£o**: `"Silva,J"` ‚Üí `"Silva, J"`
3. **Converte para mai√∫sculas**: `"Silva, j.c."` ‚Üí `"SILVA, J.C."`

**Importante**: A formata√ß√£o original √© **preservada** para exibi√ß√£o, enquanto a vers√£o normalizada √© usada apenas para matching.

### 4. Canonicaliza√ß√£o

Agrupa varia√ß√µes similares sob um **nome can√¥nico** usando algoritmos de similaridade combinados:

#### Algoritmos de Similaridade

| Algoritmo | Peso | Prop√≥sito |
|-----------|------|-----------|
| **Levenshtein** | 40% | Detecta erros de digita√ß√£o e transposi√ß√µes |
| **Jaro-Winkler** | 40% | Otimizado para strings curtas (sobrenomes) |
| **Phon√©tico (Metaphone)** | 20% | Captura varia√ß√µes fon√©ticas |

**Score final**: M√©dia ponderada ‚â• 0.70 para agrupamento

**Exemplo de agrupamento**:
```
Varia√ß√µes detectadas:
- "Forzza, R.C." (1523 ocorr√™ncias)
- "Forzza, R." (847 ocorr√™ncias)
- "R.C. Forzza" (234 ocorr√™ncias)
- "Rafaela C. Forzza" (89 ocorr√™ncias)

Nome can√¥nico: "Forzza, R.C."
Total de ocorr√™ncias: 2693
```

### Formato Can√¥nico

Para entidades do tipo **Pessoa**, o sistema aplica o formato padr√£o:

**"Sobrenome, Iniciais"**

Exemplos:
- Todas as varia√ß√µes de "Forzza" ‚Üí `"Forzza, R.C."`
- Todas as varia√ß√µes de "Silva" ‚Üí `"Silva, J."`

---

## üèóÔ∏è Arquitetura T√©cnica

### Stack Tecnol√≥gico

- **Linguagem**: Python 3.11+
- **Intelig√™ncia Artificial**:
  - **`transformers`** - Hugging Face BERT models
  - **`torch`** - PyTorch para infer√™ncia de deep learning (suporta CUDA 12.4+)
  - Modelo: `pierreguillou/bert-base-cased-pt-lenerbr` (414MB na GPU)
- **Processamento NLP**:
  - `python-Levenshtein` - C√°lculo de dist√¢ncia de edi√ß√£o
  - `jellyfish` - Jaro-Winkler e algoritmos fon√©ticos (Metaphone, Soundex)
- **Banco de Dados**:
  - **MongoDB** - Fonte de dados (4.6M registros)
  - **DuckDB** - Armazenamento local otimizado para an√°lises
- **Manipula√ß√£o de Dados**:
  - `pymongo` - Cliente MongoDB
  - `pandas` - Exporta√ß√£o CSV e processamento tabular
  - `pydantic` - Valida√ß√£o de schemas e type safety
- **Interface**:
  - `click` - CLI intuitivo
  - `tqdm` - Barras de progresso

### Modelo de Dados

```sql
-- Tabela √∫nica desnormalizada (DuckDB)
CREATE TABLE canonical_entities (
  id INTEGER PRIMARY KEY,
  canonicalName TEXT NOT NULL,
  entityType TEXT CHECK(entityType IN
    ('Pessoa', 'GrupoPessoas', 'Empresa', 'NaoDeterminado')),
  classification_confidence REAL CHECK(0.70 <= value <= 1.0),
  grouping_confidence REAL CHECK(0.70 <= value <= 1.0),
  variations JSON NOT NULL, -- Array de varia√ß√µes
  created_at TIMESTAMP,
  updated_at TIMESTAMP
);
```

**Varia√ß√µes em JSON**:
```json
[
  {
    "variation_text": "Forzza, R.C.",
    "occurrence_count": 1523,
    "association_confidence": 0.95,
    "first_seen": "2025-10-03T10:15:00Z",
    "last_seen": "2025-10-03T14:30:00Z"
  }
]
```

### Performance

#### Requisitos

- **Throughput**: ‚â•213 registros/segundo
- **Tempo total**: ‚â§6 horas para 4.6M registros
- **Overhead de IA**: ~0.03s por caso com GPU (66x mais r√°pido que CPU)
- **Mem√≥ria**: Streaming eficiente (sem carregar todos os registros em RAM)

#### Estrat√©gia de Paraleliza√ß√£o

```
MongoDB (4.6M registros)
    ‚Üì
Batch Reader (chunks de 10K)
    ‚Üì
Worker Pool (processamento sequencial - DuckDB n√£o suporta paralelo)
    ‚Üì [Pipeline completo por batch]
    ‚Üì
Results Aggregator (DuckDB com WAL)
    ‚Üì
Banco de Dados Local
```

- **Processamento Sequencial**: DuckDB n√£o suporta escritas paralelas
- **Batch processing**: Chunks de 10.000 registros
- **Cursor streaming**: MongoDB batch_size=1000 (efici√™ncia de mem√≥ria)
- **Modelo BERT**: Carregado uma vez em mem√≥ria e cacheado (GPU se dispon√≠vel)

### Garantias de Qualidade

#### Limiar de Confian√ßa

Todas as opera√ß√µes respeitam **confian√ßa m√≠nima de 0.70**:

- ‚úÖ Confian√ßa ‚â• 0.70: Aceita automaticamente
- ü§ñ Confian√ßa < 0.70: Tenta fallback de IA BERT
- ‚ö†Ô∏è Ainda < 0.70 ap√≥s IA: Sinaliza para revis√£o manual

#### Type Safety

- **Pydantic models**: Valida√ß√£o em runtime
- **mypy strict mode**: Verifica√ß√£o est√°tica de tipos
- **100% type hints**: Todo c√≥digo p√∫blico tipado

#### Testes

- **Cobertura m√≠nima**: 80% (100% em l√≥gica de neg√≥cio)
- **Contract tests**: Schemas de entrada/sa√≠da (incluindo NER)
- **Integration tests**: 7 cen√°rios de aceita√ß√£o
- **Performance tests**: Benchmarks com pytest-benchmark

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.11 ou superior (Python 3.13 testado e funcionando)
- MongoDB rodando (local ou remoto)
- 4GB RAM m√≠nimo (8GB recomendado)
- **Opcional**: GPU NVIDIA com CUDA para acelera√ß√£o de IA (66x mais r√°pido)

### Instala√ß√£o Padr√£o (CPU)

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/biopinda/coletores-BO.git
cd coletores-BO
```

2. **Crie um ambiente virtual**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements-minimal.txt
```

### Instala√ß√£o com GPU (Recomendado)

Para aproveitar acelera√ß√£o por GPU (66x mais r√°pido no NER):

#### Windows (uma vez, requer privil√©gios de administrador):

```powershell
# Habilitar caminhos longos (resolve erro de path length do PyTorch)
Set-ItemProperty -Path 'HKLM:\SYSTEM\CurrentControlSet\Control\FileSystem' -Name LongPathsEnabled -Value 1
```

#### Instalar PyTorch com CUDA:

```bash
# Python 3.13 (nightly build)
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu124

# Python 3.11-3.12 (stable)
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

#### Instalar demais depend√™ncias:

```bash
pip install -r requirements.txt
```

**Nota**: O primeiro uso far√° download autom√°tico do modelo BERT (~420MB) do Hugging Face.

### Configura√ß√£o

Edite `config.yaml`:
```yaml
mongodb:
  uri: "mongodb://localhost:27017"
  database: "dwc2json"
  collection: "ocorrencias"
  filter: { kingdom: "Plantae" }

local_db:
  type: "duckdb"
  path: "./data/canonical_entities.db"

processing:
  batch_size: 10000
  confidence_threshold: 0.70

output:
  csv_path: "./output/canonical_report.csv"
```

---

## üíª Uso

### Processamento B√°sico

```bash
python src/cli.py --config config.yaml
```

### Op√ß√µes Avan√ßadas

```bash
# Processar apenas primeiros 1000 registros (teste)
python src/cli.py --config config.yaml --max-records 1000

# Especificar arquivo de sa√≠da CSV customizado
python src/cli.py --config config.yaml
```

### M√©tricas de IA

O sistema exibe automaticamente m√©tricas de uso do NER fallback:

```
‚úÖ Pipeline complete!
   Processed: 1000 records
   Time: 87.0s
   Rate: 11.5 rec/sec
   NER fallback used: 0 times
```

### Sa√≠das Geradas

1. **Banco de dados local**: `./data/canonical_entities.db` (DuckDB)
   - Cont√©m todas as entidades can√¥nicas e varia√ß√µes
   - Persistente para an√°lises futuras

2. **Relat√≥rio CSV**: `./output/canonical_report.csv`
   - 3 colunas: `canonicalName`, `variations`, `occurrenceCounts`
   - Varia√ß√µes separadas por `;`
   - Contagens alinhadas com varia√ß√µes

**Exemplo do CSV**:

```csv
canonicalName,variations,occurrenceCounts
"FORZZA, R.C.","FORZZA, R.C.;R.C. FORZZA;RAFAELA C. FORZZA","1523;847;234"
"SILVA, J.","SILVA, J.;J. SILVA","2891;1205"
```

3. **Documenta√ß√£o de regras**: `./docs/rules.md`
   - Regras edit√°veis do algoritmo
   - Permite refinamento iterativo

---

## üìÇ Estrutura do Projeto

```
coletores-BO/
‚îú‚îÄ src/                        # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ pipeline/               # Est√°gios do pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ classifier.py       # Classifica√ß√£o (com IA)
‚îÇ   ‚îÇ   ‚îú‚îÄ ner_fallback.py     # ü§ñ BERT NER fallback (NOVO)
‚îÇ   ‚îÇ   ‚îú‚îÄ atomizer.py         # Atomiza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ normalizer.py       # Normaliza√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ canonicalizer.py    # Canonicaliza√ß√£o
‚îÇ   ‚îú‚îÄ algorithms/             # Algoritmos de similaridade
‚îÇ   ‚îÇ   ‚îú‚îÄ similarity.py       # Levenshtein, Jaro-Winkler
‚îÇ   ‚îÇ   ‚îî‚îÄ phonetic.py         # Metaphone, Soundex
‚îÇ   ‚îú‚îÄ models/                 # Modelos de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ entities.py         # Entidades Pydantic
‚îÇ   ‚îÇ   ‚îî‚îÄ contracts.py        # Contratos de dados
‚îÇ   ‚îú‚îÄ storage/                # Adaptadores de armazenamento
‚îÇ   ‚îÇ   ‚îú‚îÄ mongodb_client.py   # Cliente MongoDB
‚îÇ   ‚îÇ   ‚îî‚îÄ local_db.py         # Cliente DuckDB
‚îÇ   ‚îú‚îÄ cli.py                  # Interface CLI
‚îÇ   ‚îî‚îÄ config.py               # Gerenciamento de configura√ß√£o
‚îÇ
‚îú‚îÄ tests/                      # Testes automatizados
‚îÇ   ‚îú‚îÄ contract/               # Testes de contrato (inc. NER)
‚îÇ   ‚îú‚îÄ integration/            # Testes de integra√ß√£o
‚îÇ   ‚îî‚îÄ unit/                   # Testes unit√°rios
‚îÇ
‚îú‚îÄ docs/                       # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ fix.md                  # Instru√ß√µes de melhorias
‚îÇ   ‚îî‚îÄ NER_Implementation.md   # ü§ñ Documenta√ß√£o t√©cnica de IA (NOVO)
‚îÇ
‚îú‚îÄ config.yaml                 # Configura√ß√£o principal
‚îú‚îÄ requirements.txt            # Depend√™ncias completas (com GPU)
‚îú‚îÄ requirements-minimal.txt    # Depend√™ncias m√≠nimas (CPU only)
‚îî‚îÄ README.md                   # Este arquivo
```

---

## üõ†Ô∏è Desenvolvimento

### Executar Testes

```bash
# Todos os testes
pytest tests/

# Apenas testes de contrato
pytest tests/contract/

# Com cobertura
pytest --cov=src --cov-report=term-missing

# Testes espec√≠ficos de IA
pytest tests/contract/test_ner_schema.py -v
```

### Verifica√ß√£o de Qualidade

```bash
# Type checking
mypy src/ --strict

# Linting
ruff check src/

# Formata√ß√£o
black --check src/
```

### Adicionar Novos Padr√µes de Classifica√ß√£o

Edite `src/pipeline/classifier.py`:

```python
# Exemplo: adicionar novo padr√£o institucional
if re.match(r'^SEU_PADRAO$', text):
    return ClassificationOutput(
        original_text=text,
        category=ClassificationCategory.EMPRESA,
        confidence=0.95,
        patterns_matched=["seu_padrao"],
        should_atomize=False
    )
```

---

## üó∫Ô∏è Roadmap

### Fase 1: Implementa√ß√£o Core ‚úÖ

- [x] Estrutura do projeto
- [x] Especifica√ß√µes e planejamento
- [x] Contratos de interface
- [x] **Integra√ß√£o de IA (BERT NER com GPU)**
- [x] Implementa√ß√£o completa do pipeline
- [x] Testes automatizados (49/49 contract tests)
- [ ] Valida√ß√£o com 4.6M registros

### Fase 2: Refinamento (Futuro)

- [ ] Interface web para revis√£o manual de baixa confian√ßa
- [ ] Dashboard de m√©tricas e visualiza√ß√µes de IA
- [ ] API REST para integra√ß√£o com outros sistemas
- [ ] Fine-tuning do modelo BERT com dados espec√≠ficos de herb√°rios

### Fase 3: Escalabilidade (Futuro)

- [ ] Processamento distribu√≠do (considerando limita√ß√£o do DuckDB)
- [ ] Cache inteligente de similaridades
- [ ] Exporta√ß√£o para m√∫ltiplos formatos (JSON, Parquet)
- [ ] Versionamento de entidades can√¥nicas

---

## üìä Especifica√ß√µes T√©cnicas Detalhadas

Para informa√ß√µes t√©cnicas completas, consulte:

- **ü§ñ Documenta√ß√£o de IA**: [`docs/NER_Implementation.md`](docs/NER_Implementation.md) ‚Üê **NOVO**
- **Instru√ß√µes de Melhorias**: [`docs/fix.md`](docs/fix.md)

---

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a [Creative Commons Attribution 4.0 International License (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/).

Voc√™ √© livre para:
- **Compartilhar** ‚Äî copiar e redistribuir o material em qualquer meio ou formato
- **Adaptar** ‚Äî remixar, transformar e construir sobre o material para qualquer prop√≥sito, mesmo comercialmente

Sob os seguintes termos:
- **Atribui√ß√£o** ‚Äî Voc√™ deve dar cr√©dito apropriado, fornecer um link para a licen√ßa e indicar se mudan√ßas foram feitas

Veja o arquivo [LICENSE](LICENSE) para detalhes completos.

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## üìß Contato

**Projeto**: Sistema de Identifica√ß√£o e Canonicaliza√ß√£o de Coletores de Plantas
**Reposit√≥rio**: [https://github.com/biopinda/coletores-BO](https://github.com/biopinda/coletores-BO)
**Organiza√ß√£o**: BioPinda

---

## üôè Agradecimentos

- Herb√°rios brasileiros que disponibilizam dados abertos
- Comunidade cient√≠fica de bot√¢nica sistem√°tica
- Desenvolvedores das bibliotecas open-source utilizadas
- **Hugging Face** pela plataforma de modelos de IA
- **Pierre Guillou** pelo modelo BERT em portugu√™s brasileiro

---

Desenvolvido com üåø e ü§ñ para a ci√™ncia bot√¢nica brasileira
